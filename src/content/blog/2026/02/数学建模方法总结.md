---
title: "数学建模方法总结"
categories: Study
tags: ['数模']
id: "26afc4cae731e147"
date: 2026-02-05 19:13:18
cover: "https://zycs-img-2lg.pages.dev/v2/grlCzAk.jpeg"
---

:::note{type="success"}
本篇内容为笔者准备2026美赛时总结。
:::

# 评价决策类

## 层次分析法（AHP）

### 输入输出

- 输入： 判断矩阵：准则层的分析因素、判断矩阵的元素$a_{ij}$表示的是第 i 个因素相对于第 j 个因素的重要性比较结果
- 输出：各因素的指标权重、一致性检验结果、各方案的量化得分

### 作用

解决多目标的复杂问题的定性与定量相结合的决策分析方法，用决策者的经验判断各衡量目标之间能否实现的标准之间的相对重要程度。

### 步骤

1. 建立多级递阶的结构模型：
   1. 目标层：系统想要达到的目标或结果，是系统评价的首要准则
   2. 准则层： 是为实现目标层所设立的准则、自准则等
   3. 方案层： 是为实现目标所采取的各种方案、措施等
2. 构造两两比较判断矩阵：
   对同一级的因素/准则，以上一级要素为准则进行逐对比较，建立判断矩阵。
3. 权重计算
4. 一致性检验：
   为保证求得的权重的正确性及合理性。当随机一致性比率$C.R.<0.1$时认为计算所得的层次排序权重是正确的、合理的，否则，需要重新调整判断矩阵，直到一致性检验合格为止
5. 综合重要性的计算：
   权重最大的方案即为实现目标的最优选择

### 优点

- 系统性强：将复杂问题结构化、层次化，逻辑清晰
- 定性与定量结合： 能有效处理那些难以完全用数据量化的指标，将其转化为数值权重
- 简洁实用：原理简单，所需的定量数据少，便于操作

### 缺点：

- 主观性强：核心输入依赖于人的主观打分，如果专家判断不准，结果就会有偏差
- 指标数量限制： 每一次指标数不宜过多，否则两两比较工作量大，且难以通过一致性检验
- 粗略性： 比较标度 1-9 相对粗糙，对于精度要求高的问题可能不够精细

### 适用场景

- 优选决策： 从多个候选方案中选出最优解（例如：最佳旅游景点选择、最佳供应商选择）
- 评价体系构建： 确定评价体系中各指标的权重（例如：员工绩效考核权重、城市宜居度评价指标权重）
- 资源分配： 根据各因素的重要性比例分配资源



## 熵权法

### 输入输出

- 输入： 至少两项或以上的定量变量（可以是效应性变量/成本性变量）
- 输出： 输入定量变量对应的权重值

### 作用

用信息熵来判断某个指标的离散程度，最终反映出该指标对综合评价的影响（权重），为多指标综合评价提供依据

### 步骤

1. 数据归一化处理：
   对于效应性变量：
   $$
   z_{ij} = \frac{X_{ij}-X_{min}}{X_{max}-X_{min}}
   $$
   对于成本性变量：
   $$
   z_{ij} = \frac{X_{max}-X_{ij}}{X_{max}-X_{min}}
   $$

2. 计算比重$p_{ij}$

3. 计算信息熵$e_{j}$

4. 计算信息效用值$d_{j}$

5. 计算权重$w_{j}$

6. 计算综合得分

### 优点

- 客观性强： 结果完全依赖数据本身，没有人为干扰
- 挖掘信息： 能敏锐捕捉到数据中的变化差异，利用数据差异进行评价

### 缺点

- 忽略实际意义： 只看数据差异，不看指标含义。如果某个关键指标在所有样本中数值很接近，但从业务逻辑上它又至关重要，此时绝不能单独使用熵权法。
- 对异常值敏感： 数据中的噪音或极端值会显著拉偏权重

### 适用场景

- 有大量客观数据支持的评价问题
- 需要 AHP 之外提供另一种视角进行验证





## 组合赋权：AHP+熵权法

### 作用

将 AHP 与熵权法结合，即尊重专家的经验判断，又尊重数据的客观规律

### 方法

线性加权：
$$
W_{综合} = \alpha W_{AHP} + (1-\alpha)W_{熵权}
$$

- $\alpha$： 
  - 如果没有特殊偏好，取$\alpha =0.5$
  - 如果题目数据质量不好，可以偏向 AHP，反之亦然。 



## 模糊综合评价

 ### 作用

对实际的综合评价问题提供评价。将一些边界不清、不易定量的因素定量化，进而进行综合性评价的一种方法。最终得到一个整体的评价结果。

### 输入输出

- 输入：评价指标、评语、模糊矩阵
- 输出： 反应考核指标在量化评价中的综合得分

### 步骤

1. 确定评价指标与评语的等级，确定模糊矩阵
2. 计算权重
3. 计算评语等级的隶属度
4. 计算综合得分

### 优点

- 更符合客观世界：解决了“一刀切”评价的生硬问题
- 定性转定量： 适合处理那些语言化、难以量化的指标
- 信息保留完整： 相比于直接给一个分，它保留了对象在各个等级上的分布信息

### 缺点

- 隶属度函数难定： 如何确定“隶属度”（即构建矩阵 R）是最大的难点，往往需要依赖专家打分或统计分布，带有主观性
- 计算复杂度： 如果指标层级过多，计算量会变大
- 分辨力可能失效： 当指标极多且权重非常分散时，计算出来的结果向量可能各项数值都很接近，导致无法区分优劣。

### 适用场景

- 满意度调查
- 坏境评估： 空气质量等级（一级、二级、三级……往往界限是渐变的）
- 风险评估： 项目风险等级
- HR 绩效考核： 员工综合素质评价



## TOPSIS法

### 作用

充分利用原始数据的信息，其结果能精确地反映各评价方案之间的差距。

### 输入输出

- 输入： 评价矩阵（评价指标和数值）
- 输出： 反应考核指标在量化评价中的综合得分

### 步骤

1. 数据预处理：正向化与归一化
2. 确定指标权重：熵权法/AHP/其他
3. 计算最优解与最劣解
4. 计算与最优解和最劣解的距离
5. 计算综合得分与排序

### 优点

- 充分利用原始数据： 基于原始数据计算距离，信息损失少，能精确反映各方案之间的细微差异
- 对样本无严格限制： 不需要大样本，不需要样本服从正态分布
- 结果直观

### 缺点

- 依赖外部权重： 自身无法确定指标权重，需结合 AHP 或熵权法
- 逆序问题： 是一个理论上的缺陷。有时候引入一个新的（表现一般的）方案，可能会导致原本排第一和第二的方案顺序互换
- 对异常值敏感： 如果某个方案在某项指标上表现得好得离谱（极端值），会拉大理想解的距离，导致评价结果失真

### 适用场景

- 多指标决策分析
- 绩效评估
- 医疗/工程方案优选



## 灰色关联分析

### 作用

对一个系统发展变化态势的定量描述和比较方法，反映两个因素变化的趋势的关联性。可以进行因素分析、综合评价

### 输入输出

- 输入：母序列、比较序列
- 输出： 反映考核指标与母序列的关联程度

### 步骤

1. 确定母序列和比较序列
2. 无量纲化处理：
   初值化方法适用于稳定递增或递减的数据，而均值化适合没有明显升降趋势现象的数据
3. 计算关联系数
4. 计算关联度：
   关联度为关联系数的加权平均
5. 关联度排序

### 优点

- 小样本： 只要有四个以上的数据点就能算，不需要海量数据
- 不假设分布： 不需要数据服从正态分布，也不要求线性关系，适用性广
- 计算简单： 公式简单，结果稳定，不会因为增加几个数据就导致结论反转

### 缺点

- 分辨力系数$\rho$的主观性：$\rho$的取值主要靠经验，取值不同可能会影响最终排序
- 相对粗糙： 主要分析趋势，对具体的数值大小不如回归分析那么敏感
- 标准化敏感： 采用不同的无量纲化方法，可能会算出不同的结果

### 适用场景

- 小样本因素分析
- 动态过程评价
- 多指标评价
- 与 TOPSIS 法结合：“为了保证评价结果的稳健性，本文分别采用了 TOPSIS 法和灰度关联分析法对方案进行排序。结果显示，两种方法得到的排名高度一致，证明了模型的可靠性”



## 秩和比综合评价法

### 作用

对评价对象的优劣直接排序或分档排序，从而对评价对象做出综合评价，特别适合将对象分档次。

### 输入输出

- 输入： 原始数据矩阵
- 输出： 反映考核指标在量化评价中的综合得分与分档

### 步骤

1. 数据处理：同趋势处理和归一化处理

2. 非整秩编秩计算
   $$
   R_{ij} = 1 + (n-1)z_{ij}
   $$

3. 计算权重：熵权法/AHP/默认平均权重

4. 计算加权秩和比（WRSR）

5. Probit 分档与回归分析

6. 最终分档结果

### 优点

- 鲁棒性极强： 能够有效消除异常值的干扰。
- 分类功能： 结合统计学原理给出分档
- 兼容性好：既可以单独使用，也可以加入权重

### 缺点

- 信息损失：把数值变成排名，丢失了具体的数量差异信息
- 区分度较弱： 当样本较少或者指标较少时，容易出现 RSR 值相同的情况，难以精确区分前几名

### 适用场景

- 医疗质量评价
- 产品分级
- 数据波动大
- 与 TOPSIS 结合：用 TOPSIS 计算出精确的得分，再用 RSR 对这些得分进行回归分析和分档



# 数理统计类

## 时间序列模型

### ARIMA模型

#### 作用

是统计模型中最常见的一种用来进行时间序列预测的模型

#### 输入输出

- 输入： 特征序列为 1 个时间序列数据定量变量
- 输出： 未来 N 天的预测值

#### 步骤

1. 时间序列的平稳性检验：
   通常采用 ADF 或 PP 检验方法，对原始序列进行单位根检验，如果时间序列不满足平稳性条件，可以通过差分变换或者对数差分变换，将非平稳时间序列转化为平稳时间序列，然后对平稳时间序列构建 ARIMA 模型
2. 确定模型的阶数
3. 参数估计与诊断检验：
   包括检验模型参数的显著性，模型本身的有效性以及检验残差序列是否为白噪声序列，如果模型通过检验，则模型设定基本正确，否则，必须重新确定模型的形式，并诊断检验，直到得到设定正确的模型形式
4. 用建立的 ARIMA 模型进行预测

#### 优点

- 解释性极强： 数学原理清晰，通过 ACF/PACF 图直观解释数据特征
- 小数据：对小样本数据表现往往优于深度学习模型
- 速度快：训练速度快
- 短期预测精度高

#### 缺点

- 无法捕捉非线性关系
- 无法处理海量数据或多变量耦合
- 长期预测能力差

#### 适用场景

- 短期趋势预测
- 数据量较少时
- 作为对比基准
- 数据相对平稳或有简单趋势


### 灰度预测模型

#### 作用

针对含有不确定因素、不完全信息或者少量数据样本的系统进行预测的有效方法。基于处理后的数据序列建立一阶单变量微分方程模型，从而实现对事物未来发展趋势的预测

#### 输入输出

- 输入： 1 个时间序列数据定量变量
- 输出： 拟合预测结果、模型精度

#### 步骤

1. 数据准备（平移变换）
2. 级比检验
3. 累加序列生成
4. 紧邻均值序列
5. 构建矩阵 B 和向量 Y
6. 最小二乘估计参数 a 和 b
7. 预测模型建立
8. 还原预测值
9. 模型检验

#### 优点

- 对数据量要求极低
- 不需要数据服从任何统计分布

#### 确定

- 只适合中短期预测
- 对数据波动敏感
- 仅适用于指数增长或者衰减趋势

#### 适用场景

- 数据极度匮乏时
- 呈指数增长趋势的数据：
  细菌繁殖、早期传染病传播、GDP 快速增长期、硬盘容量增长等
- 作为辅助验证模型



### LSTM模型

#### 作用

捕捉长距离依赖，处理非线性曲线，预测

#### 输入输出

- 输入： 时间序列
- 输出： 预测值

#### 步骤

1. 数据预处理：归一化
2. 滑动窗口构建
3. 模型搭建
4. 训练与验证
5. 反归一化

#### 优点

- 拟合能力强
- 多变量支持：支持多变量输入，可以融合多个特征
- 能够保留较长期特征
- 鲁棒性好：对噪声数据有更好的抗干扰能力

#### 缺点

- 黑盒模型
- 训练慢，对算力要求高
- 对于超长序列，效果不如 transformer
- 容易过拟合

#### 适用场景

- 大数据量的时间序列（1000+）
- 多变量耦合预测
- 高度非线性的复杂系统
- 作为对比组



## 计量统计



### 线性回归

#### 作用

利用数理统计中的回归分析，来确定两种或两种以上变量间相互依赖的定量关系

#### 输入输出

- 输入： 
  自变量 X：至少包含一项或以上的定量变量，如果自变量包含二分类定类变量，需要将这些变量转化为哑变量。
  因变量 Y： 定量变量，如果因变量是定类变量，则应考虑逻辑回归或者其他适当的分类模型
- 输出： 模型检验优度的结果，自变量对因变量的线性关系

#### 步骤

1. 矩阵构造
2. 计算$X^{T}X$和$X^{T}Y$
3. 求逆矩阵$(X^{T}X)^{-1}$
4. 计算自回归系数
5. 计算标准误差
6. 模型评估统计量
7. 最终模型公式

#### 优点

- 形式简单，可解释性强
- 建模速度快
- 数学理论完善

#### 缺点

- 线性假设限制
- 对异常值敏感
- 多重共线性问题：如果自变量之间高度相关，会导致模型参数估计极其不稳定

#### 适用场景

- 趋势外推/短期预测
- 影响因素分析
- 基准模型



### 岭回归

#### 作用

专用于共线性（即自变量之间高度相关）数据分析的有偏估计回归方法，用于研究变量之间的关系以及估计因变量基于自变量的变化情况。

#### 输入输出

- 输入： 
  自变量 X：至少包含一项或以上的定量变量，如果自变量包含二分类定类变量，需要将这些变量转化为哑变量。
  因变量 Y： 定量变量，如果因变量是定类变量，则应考虑逻辑回归或者其他适当的分类模型
- 输出： 模型检验优度的结果，自变量对因变量的线性关系

#### 步骤

1. 数据标准化
2. 构建岭迹图
3. 确定最佳$\lambda$值
4. 模型求解与评估

#### 优点

- 稳定性强： 在处理多重共线性时，比普通线性回归更稳健
- 防止过拟合： 通过压缩系数，使模型泛化能力更强
- 计算成本低

#### 缺点

- 有偏估计：拟合优度 $R^2$通常会比普通线性回归略低
- 无法做变量筛选

#### 适用场景

- 特征之间高度相关（多重共线性）
- 样本量少于特征数
- 模型系数出现反常



### 逻辑回归

#### 作用

研究多分类因变量与一些影响因素之间关系的一种多变量分析方法

#### 输入输出

- 输入： 因变量 Y 为分类变量，自变量 X 为至少一项定量变量或定类变量
- 输出： 逻辑回归系数估计以及分类预测的效果评价

#### 步骤

1. 参数设置：类别设置
2. 用近似法求$w_1,w_2,b$
3. 确定模型
4. 预测样本

#### 优点

- 结果可解释性强
- 计算代价低
- 无需假设数据分布

#### 缺点

- 容易过拟合：分类边界只能是线性的，对于非线性可分的数据效果很差
- 对多重共线性敏感
- 数据不平衡问题：如果正负样本比例极度失衡，模型会倾向于把所有样本都判为多数类

#### 适用场景

- 二分类问题
- 需要概率值的场景
- 寻找危险因素



### K-Means聚类

#### 作用

通过迭代，将样本分组成 k 个簇，使得每个样本与其所属类的中心或均值的距离之和最小。

#### 输入输出

- 输入： 1 个或 1 个以上的定类变量或定量变量，预先设定类别个数
- 输出： 根据预先设定的类别个数，划分为其设定的类别

#### 步骤

1. 数据预处理
2. 初始化质心
3. 分配样本到最近质心
4. 更新质心
5. 迭代至收敛

#### 优点

- 原理简单、直观
- 速度快
- 可调节性：只需要调整 K 值就能观察到不同粒度的分类结果



#### 缺点

- k 值难定：解决方法：手肘法
- 对初值敏感：随机选取的初始质心不同，最终结果可能完全不同。解决方法：K-Means++
- 对异常值敏感：一个离群点可能会把中心点拉的很远
- 形状限制：假设簇是球状的（凸集）

#### 适用场景

- 客户细分
- 选址问题
- 图像压缩
- 异常检测



### 分层聚类

#### 作用

对给定数据对象的集合进行层次分解。

#### 输入输出

- 输入： 一个以上的定量变量和可选的索引项
- 输出： 个体或者变量被划分的类别和树状图

#### 步骤

1. 初始化：把每个样本各自归为一类，计算每两个类之间的距离
2. 寻找各个类之间最近的两个类，把他们归为一类
3. 重新计算新生成的类与各个旧类之间的距离
4. 重复 2、3 步，直到所有的样本都归为一类

#### 优点

- 无需预设 k 值
- 结果信息丰富：不仅知道谁和谁一类，还能知道他们的亲缘关系的远近
- 适合小样本

#### 缺点

- 计算复杂度极高
- 对异常值敏感

#### 适用场景

- 样本量较小
- 分类数量不确定
- 生物/分类学研究
- 寻找层次关系



### 主成分分析（PCA）

#### 作用

将多个有一定相关性的指标进行线性组合，以最少的维度解释原数据中尽可能多的信息为目标进行降维，消除多重共线性。

#### 输入输出

- 输入： 2个或2个以上的定量变量
- 输出： 若干个变量

#### 步骤

1. 数据标准化
2. 计算相关系数矩阵
3. 计算特征值与特征向量
4. 计算主成分得分
5. 计算综合得分

#### 优点

- 消除相关性
- 无参数限制：不需要调参

#### 缺点

- 解释性差
- 线性假设

#### 适用场景

- 指标太多，需要降维
- 构建综合评价体系
- 图像压缩/去噪



### 双重差分DID

#### 作用

评估某些政策或时间产生的净效应。

#### 输入输出

- 输入： 
  - 面板数据
  - 分组变量
  - 时间变量
  - 控制变量
- 输出：
  - 交叉项系数
  - 显著性

#### 步骤

标准的 DID 回归方程如下：

$$Y_{it} = \beta_0 + \beta_1 Treat_i + \beta_2 Post_t + \mathbf{\beta_3 (Treat_i \times Post_t)} + \mu X_{it} + \epsilon_{it}$$

- $Y_{it}$: 结果变量。
- $Treat_i$: 组别效应（处理组为1）。
- $Post_t$: 时间效应（政策后为1）。
- **$Treat_i \times Post_t$**: **交互项，这是模型的灵魂！**
- $\beta_3$: **这就是 DID 估计量 (Treatment Effect)**。如果 $\beta_3 > 0$ 且显著，说明政策起到了正向作用。

#### 优点

- 解决内生性问题
- 逻辑清晰，公信力强
- 操作简便

#### 缺点

- 平行趋势假设
- 数据要求高
- 外溢效应

#### 适用场景

- 政策评估
- 自然灾害/突发事件影响



### PSM-DID

#### 作用

结合 PSM(倾向得分匹配)和 DID（双重差分）的优势，主要用于解决非随机分组带来的选择偏差

#### 输入输出

- 输入：
  - 面板数据
  - 匹配变量
  - DID 变量
- 输出：
  - 匹配后的样本
  - 净效应
  - 平衡性检验结果

#### 步骤

**计算倾向得分 (Propensity Score Estimation):**

- 使用 **Logit** 或 **Probit** 回归，以“是否受到政策干预 ($Treat$)”为因变量，各种特征变量 ($X$) 为自变量，计算每个样本进入处理组的概率（即倾向得分）。

**匹配 (Matching):**

- 根据得分进行配对。最常用的是 **k-近邻匹配 (k-Nearest Neighbor)**（比如 1:1 或 1:4 匹配）或 **核匹配 (Kernel Matching)**。
- *直观理解：* 给每个“处理组城市”找一个得分最接近的“对照组城市”。

**平衡性检验 (Balance Test):** **(关键步骤！)**

- 检查匹配后，处理组和对照组在各个特征上是否还有显著差异。理想情况是：**匹配后，两组在统计上没有区别**（标准偏差Bias < 10%）。

**运行 DID:**

- 只保留**匹配成功**的样本，在这些样本上运行标准的 DID 回归模型。

#### 优点

- 双重保险
- 缓解平行趋势假设

#### 缺点

- 数据浪费
- 无法解决“时变”的不可观测因素

#### 适用场景

- 基准 DID 效果不好时
- 个体差异巨大的自然实验
- 自选性很强的政策



### 断点回归

#### 作用

RDD 利用了一个规则：个体的处理状态（是否受到干预）完全取决于某个**驱动变量 (Running Variable)** 是否超过了特定的**阈值 (Cutoff)**。

#### 输入输出

- 输入：
  - 驱动变量 X
  - 断点/阈值
  - 处理变量
  - 结果变量
- 输出：
  - 断点效应

#### 步骤

一个简单的线性 RDD 模型如下：

$$Y_i = \alpha + \beta_1 (X_i - c) + \tau D_i + \beta_2 (X_i - c)D_i + \epsilon_i$$

- $X_i - c$: 这里的去中心化是为了让截距更有意义。
- $\tau$: **这就是我们要求的局部平均处理效应 (LATE)**。
- $\beta_2$: 允许断点左右两侧的斜率不同。

#### 优点

- 内部有效性极高
- 假设较弱
- 直观

#### 缺点

- 局部有效性
- 样本量要求大
- 操纵检验

#### 适用场景

- 教育领域
- 社会保障
- 环境政策



## 机器学习

### BP神经网络

#### 作用

非线性映射。用于拟合/回归、分类、降维/特征提取

#### 输入输出

- 输入： 一系列数据
- 输出： 
  回归问题：输出连续值
  分类问题：输出概率或者类别

#### 步骤

1. 数据预处理：缺失值填补、异常值剔除、归一化、划分训练集、验证集、测试集
2. 网络结构确定
3. 模型训练
4. 模型评价与验证：适用 $R^2$、MSE、MAE 或准确率、混淆矩阵评价

#### 优点

- 强大的非线性映射能力
- 自学习与自适应

#### 缺点

- 黑箱模型
- 容易陷入局部最优
- 过拟合



### 随机森林

#### 作用

强鲁棒性的预测/分类，特征重要性评估

#### 输入输出

- 输入： X（特征矩阵）
- 输出： 
  分类：类别
  回归：预测
  附加输出：特征重要性排序

#### 步骤

1. Bootstrap 重采样
2. 决策树构建
3. 结果聚合
4. 模型分析

#### 优点

- 自带特征选择/解释性：能够解释特征的重要性
- 抗过拟合能力强
- 数据预处理简单： 对异常值不敏感，不需要归一化

#### 缺点

- 回归预测不连续： 在回归问题中不能输出超出训练集范围的值（无法外推），且输出是阶梯状的
- 黑箱：看不出具体的函数关系式

#### 适用场景

- “因素分析”类问题：哪些因素对结果影响最大？筛选出关键指标
- 高维小样本数据： 特征很多，但样本很少
- 处理混合数据



### 决策树

#### 作用

通过一种树形结构来进行决策。可以用于直观的决策支持和规则提取

#### 输入输出

- 输入：特征矩阵
- 输出： 
  分类树：叶子节点代表类别
  回归树：叶子节点代表该区域内样本的均值
  路径：从根节点到叶子节点的完整判断逻辑

#### 步骤

1. 特征选择：决定用哪个特征、在哪个值进行切分
2. 树的生成：递归地分割数据，直到满足停止条件
3. 剪枝：为了防止过拟合，需要剪枝
   预剪枝：限制最大深度或者叶子节点最小样本数
   后剪枝：先长成大树，再根据验证集精度剪掉多余枝叶

#### 优点

- 极致的可解释性
- 非线性且无需预处理

#### 缺点

- 容易过拟合
- 不稳定性：数据变动一点点，生成的树可能完全不同。
- 正交边界：决策边界只能是平行于坐标轴的直线，处理倾斜边界效果不好

#### 

#### 适用场景

- 题目要求制定“具体规则”或策略
- 画出漂亮的流程图来填充版面
- 作为复杂模型的“代理解释器”：用决策树来解释神经网络的逻辑



### 支持向量机

#### 作用

分类、回归

#### 输入输出

- 输入： 特征矩阵
- 输出： 
  分类：类别标签
  回归：连续预测值

#### 步骤

1. 数据标准化
2. 核函数选择：
   - Linear（线性核）：特征多，样本少时用
   - RBF（高斯核）：适用于非线性关系
   - Ploy（多项式核）：较少用，参数难调
3. 参数寻优
4. 模型训练与求解

#### 优点

- 小样本表现极佳
- 数学理论严备
- 泛化能力强

#### 缺点

- 对缺失值/噪声敏感
- 大规模数据太慢
- 多分类稍显笨重

#### 适用场景

- 小样本的高维分类、回归
- 非线性小数据
- 二分类问题





### 朴素贝叶斯

#### 作用

是基于贝叶斯定理和特征条件独立假设的分类算法

- 计算后验概率
- 文本分类/情感分析
- 多分类基准

#### 输入输出

- 输入：X
  离散型数据：效果最好
  连续性数据：需要假设其服从高斯分布
- 输出： 
  概率值：样本属于各个类别的概率
  类别：概率最大的那个类

#### 步骤

1. 假设提出：
   核心假设：各个特征之间相互独立
2. 计算先验概率
3. 计算条件概率
4. 贝叶斯公式求解

#### 优点

- 数学逻辑极其清晰
- 极速与高维适应
- 小样本表现好

#### 缺点

- 特征独立性假设太强
- 对输入形式敏感：尽量将连续数据离散化后再用

#### 适用场景

- 自然语言处理（NLP）
- 垃圾邮件/欺诈检测
- 多分类问题的 baseline



### XGBoost

#### 作用

极致的回归与分类

#### 输入输出

- 输入：特征矩阵
- 输出：
  - 原理值
  - 特征重要性

#### 步骤

1. 目标函数构建
2. 二阶泰勒展开
3. 树的生成
4. 结果累加

#### 优点

- 精度天花板
- 内置正则化
- 自动处理缺失值

#### 缺点

- 参数极其复杂
- 黑箱模型
- 容易过拟合噪声

#### 适用场景

- 追求极致精度的预测
- 数据存在大量缺失值
- 特征筛选



### LightGBM

#### 作用

- 极速回归/分类
- 处理海量数据

#### 输入输出

- 输入： 特征矩阵
- 输出： 预测值

#### 步骤

1. 基于直方图的算法
2. 带有深度限制的 leaf-wise 生长策略
3. 单边梯度采样

#### 优点

- 训练速度快
- 内存占用低
- 极度高

#### 缺点

- 过拟合风险高
- 参数条件敏感：必须要调 num_leaves 参数

#### 适用场景

- 大数据量的回归/分类
- 高维稀疏特征
- 多分类问题



## 相关性分析



### 相关性分析

#### 作用

- 探索关系：发现变量之间是否存在某种规律
- 特征筛选：在机器学习中，通过相关性分析剔除与目标变量无关的冗余特征，或者识别可能导致多重共线性的强相关自变量
- 假设严重：验证理论上的因果链条，前提条件与结果是否存在统计学上的联系
- 预测基础：它是回归分析的前提，只有变量间存在相关性，建立回归模型才有意义



#### 输入输出

- 输入：两个或两个以上的定量变量或有序定类变量
- 输出：两两定类变量之间是否呈现显著性相似以及相似的程度

#### 步骤

1. 数据清洗
2. 正态性检验：观察数据分布。如果符合正态分布，首先 Pearson 系数
3. 绘制散点图：直观观察变量间是否有线性趋势，防止被非线性关系误导
4. 计算相关系数

- Pearson 相关系数：适用于定量数据，且数据满足正态分布
  $$
  r =\frac{\sum\limits_{i=1}^{n}(X_{i}-\bar{X})(Y_{i}-\bar{Y})}{{\sqrt{\sum\limits_{i=1}^{n}(X_{i}-\bar{X})^2}\sqrt{\sum\limits_{i=1}^{n}(Y_{i}-\bar{Y})^2}}}
  $$

- Spearman 相关系数：数据不满足正态分布时使用
  $$
  \rho =1-\frac{6\sum d_{i}^2}{n(n^2-1)}
  $$

- Kendall's Tau-b 相关系数：适用于有序定类变量
  $$
  \tau_{b} = \frac{P-Q}{\sqrt{(P+Q+T)(P+Q+U)}}
  $$
  其中 P是一致对的数量，Q 是不一致对的数量，T 是仅在 x 中的系数，U 是仅在 y 中的系数。

5. 显著性检验：查看 P 值
6. 结果解读

#### 优点

- 简单直观
- 方向明确

#### 缺点

- 不代表因果：相关不等于因果
- 局限线性
- 易受异常值影响

#### 适用场景

- 探索关系：发现变量之间是否存在某种规律
- 特征筛选：在机器学习中，通过相关性分析剔除与目标变量无关的冗余特征，或者识别可能导致多重共线性的强相关自变量
- 假设严重：验证理论上的因果链条，前提条件与结果是否存在统计学上的联系
- 预测基础：它是回归分析的前提，只有变量间存在相关性，建立回归模型才有意义



### 一致性检验

#### 作用

防止逻辑矛盾

#### 输入输出

- 输入： 判断矩阵
- 输出：一致性比率 CR

#### 步骤

1. 构造判断矩阵

2. 计算最大特征值

3. 计算一致性指标
   $$
   CI = \frac{\lambda_{max}-n}{n-1}
   $$

4. 查找平均随机一致性指标 RI

5. 计算一致性比率 CR
   $$
   CR =\frac{CI}{RI}
   $$

6. 判定:

   - 若 CR<0.10，认为判断矩阵的一致性可以接受
   - 若 CR>=0.10，需要对判断矩阵进行修正

#### 优点

- 科学性
- 容错性

#### 缺点

- 维度限制：当指标数量 n 较大时，很难通过一致性检验
- RI 的经验性：RI 值是统计得来的，并没有严格的数学推导公式

#### 适用场景

- 评价类模型：AHP
- 决策分析
- 无法获取大量数据：只能依靠专家打分或主观经验



### 一致性评价



#### 作用

需要验证人工标注质量，或者对比两个分类模型时使用。衡量两个评价者对同一组对象进行分类时的一致程度，且排除了随机猜对的可能性

#### 输入输出

- 输入：一个混淆矩阵
- 输出：k 值

#### 步骤

1. 计算观测一致率$P_0$：两个人都说对的比例

2. 计算随机一致率$P_e$：假设两个人是独立随机猜的，猜对的概率期望

3. 代入公式（Cohen's Kappa）
   $$
   k = \frac{P_{0} - P_{e}}{1-P_{e}}
   $$

4. 判定：

   - k>0.8：几乎完美一致
   - k>0.6：高度一致
   - k<0.4：一致性差

#### 优点

- 比单纯的准确率更科学

#### 缺点

- 只适合与分类变量，不适合连续评分

#### 适用场景

- 医生诊断对比
- 数据标注质量
- 模型分类对比



## 差异分析

### 作用

- 验证区别：判断观察到的差异是由于随机误差造成，还是本质上就不同
- 模型对比：证明新模型在准确率或者运行时间上显著由于基准模型
- 政策评估：比较政策实施前后的数据变化

### 输入输出

- 输入：
  分组变量（自变量 X）：通常是分类变量
  数值变量（因变量 Y）：具体的观测数值
- 输出：
  统计量：如 t 值，F 值，卡方
  P 值：核心指标
  效应量

### 步骤

1. 正态性检验
2. 方差齐性检验
3. 选择检验指标：![img](https://s0.spsspro.com/sp-webfed/help/img/1638960185720-a33a2cd9-8417-4e21-92d2-7fe89b248684.png)
4. 可视化



### 适用场景

- 模型性能对比
- 社会科学/政策影响
- 多方案优选



# 运筹优化类

## 线性规划

### 作用

在有限的资源约束下，寻找最优解。在满足一系列线性约束条件的前提下，求一个线性目标函数的极值

### 输入输出

- 输入：
  - 决策变量：需要控制的量
  - 目标函数系数
  - 约束条件参数
  - 变量边界
- 输出：
  - 最优决策方案
  - 最优目标值
  - 灵敏度分析

### 步骤

1. 定义决策变量：
   明确哪些量是可以控制的？用数学符号表示
2. 确立目标函数
3. 列出约束条件：
   把限制写出线性等式或不等式
4. 规定非负约束

### 优点

- 全局最优性：只要有解，必定是全局最优
- 求解速度快
- 理论成熟
- 灵敏度分析：可以量化“资源价值”，便于后续的深入讨论

### 缺点

- 线性假设强
- 变量连续性
- 确定性假设

### 适用场景

- 生产计划问题
- 配料/混合问题
- 运费/指派问题
- 网络流问题
- 多阶段投资问题



## 整数规划

### 作用

在满足线性约束的前提下，求整数解的最优方法。

### 输入输出

- 输入：
  - 同线性规划
  - 整数限制
  - 二值限制：指定某些变量只能取 0/1
- 输出：
  - 整数解
  - 最优目标值

### 步骤

1. 定义决策变量：
   - 特别是引入$y_i =0/1$
2. 确立目标函数
3. 列出约束条件：
   - 互斥约束：两个项目只能选一个：$x_1 + x_2 <= 1$
   - 依赖约束：只有选了 A 才能选 B：$x_B<=x_A$
   - 固定成本： 如果生产产品 x，必须支付开机费 K：$Cost =c·x + K·y$（y 是 0-1 变量）
4. 规定非负约束
5. 规定整数/0-1 约束

### 优点

- 真实性强
- 逻辑表达能力强
- 适用面广

### 缺点

- 求解困难
- 灵敏度分析困难
- 对求解器要求高

### 适用场景

- 指派问题：N 个人做 N 件事
- 背包问题：物品体积价值不同，背包容量有限
- 选址问题：在 10 个备选点中选 3 个建物流中心
- 排班/调度问题
- 路径规划问题



## 非线性规划

### 作用

处理目标函数或者约束条件中包含非线性项的优化问题。

### 输入输出

- 输入： 
  - 决策变量
  - 非线性目标函数
  - 非线性约束
  - 初始值
- 输出：
  - 局部最优解
  - 全局最优解： 很难保证找到，除非模型是凸的
  - 梯度/Hessian 矩阵：描述在最优解附近曲面的弯曲程度，用于分析稳定性

### 步骤

1. 定义决策变量
2. 确立目标函数
3. 列出约束条件
4. 判断凸性
5. 选择求解算法

### 优点

- 高度逼真
- 灵活性强

### 缺点

- 局部最优陷阱
- 求解难度大
- 数值稳定性差

### 适用场景

- 投资组合优化
- 曲线拟合：最小二乘法
- 工程设计
- 选址问题



## 图论

### 最短路径法

#### 作用

在一个加权图中，寻找两个节点之间累计权重最小的路径

#### 输入输出

- 输入：
  - 节点集合
  - 边集合
  - 权重矩阵
- 输出：
  - 最短路径值
  - 路径序列

#### 步骤

1. 抽象节点与边
2. 定义权重
3. 选择算法
4. 求解与还原路径

#### 优点

- 全局最优
- 算法成熟高效
- 易于扩展

#### 缺点

- 负权回路失效
- 内存消耗
- 静态假设：标准算法假设路况（权重）不变。

#### 适用场景

- 交通/物流导航
- 网络路由协议
- 设备更新/生产计划
- 管道铺设/布线
- 社交网络分析



### 最小生成树

#### 作用

在一个连通加权图中，找到最小生成树

#### 输入输出

- 输入： 
  - 节点集合
  - 边集合
  - 权重
- 输出：
  - 选定的边集合
  - 最小总权重
  - 树的结构

#### 步骤

1. 识别需求
2. 构建图
3. 选择算法

#### 优点

- 全局最优且高效
- 结果简单

#### 缺点

- 鲁棒性差
- 单点路径不优：从 A 到 B 可能要绕很远的路，远不如直接 A-B。

#### 适用场景

- 基础设施建设：电力网、通信网、供水管道、燃气管道
- 聚类分析：基于 MST 的聚类
- 近似 TSP
- 图像分割



## 启发式算法

### 模拟退火算法

#### 作用

在庞大的搜索空间中寻找全局最优解

#### 输入输出

- 输入： 
  - 目标函数
  - 解空间
  - 初始解
  - 控制参数：初始温度、终止温度、降温系数、马尔可夫链长度
- 输出：
  - 近似全局最优解
  - 最优目标函数值

#### 步骤

1. 初始化 (Initialization):

- 随机生成初始解 $x_{current}$，计算其目标函数值 $E_{current} = f(x_{current})$。
- 设定初始温度 $T = T_{max}$。

2. 外层循环 (降温过程):*当 $T > T_{min}$ 时，执行以下步骤：

3. **内层循环 (等温过程/Metropolis抽样):** 重复 $L$ 次：

   - **产生新解:** 在当前解 $x_{current}$ 附近进行扰动（例如：交换两个城市的顺序、微调参数值），产生新解 $x_{new}$。

   - **计算增量:** 计算能量差（目标函数差值） $\Delta E = f(x_{new}) - f(x_{current})$。

   - **接受判断 (Metropolis准则):**

     - **情况 A ($\Delta E < 0$):** 新解更优（能量更低），**直接接受**。令 $x_{current} = x_{new}$。

     - **情况 B ($\Delta E > 0$):** 新解更差，但**以概率 $P$ 接受**。

       $$P = \exp\left(-\frac{\Delta E}{T}\right)$$

       (注意：温度 $T$ 越高，接受差解的概率 $P$ 越大；随着 $T$ 降低，$P$ 迅速减小，算法趋于贪心)。

4. **降温 (Cooling):**

   - 更新温度：$T = T \times \alpha$。

5. 终止 (Termination):

- 输出搜索过程中记录到的历史最优解 $x_{best}$。

#### 优点

- 全局搜索能力强
- 通用性强
- 鲁棒性好：对初值不敏感

#### 缺点

- 收敛速度慢
- 参数敏感

#### 适用场景

NP-Hard组合优化问题

- TSP 问题
- 排班/调度问题
- 选址问题
- 布局优化
- 连续函数优化



### 遗传算法

#### 作用

全局搜索与优化

#### 输入输出

- 输入：
  - 适应度函数：即目标函数
  - 编码方式
  - 控制参数：种群规模、交叉概率、变异概率、最大迭代次数
- 输出：
  - 进化结束后的最优个体
  - 最优适应度值

#### 步骤

1. 编码
2. 初始化种群
3. 循环迭代
4. 终止

#### 优点

- 并行搜索能力强
- 可拓展性强
- 适合于多目标优化

#### 缺点

- 效率较低
- 编码困难
- 参数敏感

#### 适用场景

- 复杂的组合问题
- 多目标规划



### 粒子群算法

#### 作用

全局优化

#### 输入输出

- 输入：
  - 目标函数
  - 解空间维度
  - 控制参数：种群规模、惯性权重、学习因子、最大速度

- 输出：
  - 全局最优位置
  - 最优适应度值

#### 步骤

**1. 初始化 (Initialization):**

- 随机生成 $N$ 个粒子的初始位置 $X$ 和初始速度 $V$。
- 初始化每个粒子的个体最优解 $Pbest = X$。
- 找到初始群体中的全局最优解 $Gbest$。

**2. 循环迭代 (Iteration Loop):**

对于每个粒子 $i$：

- **更新速度 (Velocity Update):**

  这是 PSO 的灵魂公式：

  $$v_{i}^{t+1} = \underbrace{w \cdot v_{i}^{t}}_{\text{惯性}} + \underbrace{c_1 \cdot r_1 \cdot (Pbest_i - x_{i}^{t})}_{\text{自我认知}} + \underbrace{c_2 \cdot r_2 \cdot (Gbest - x_{i}^{t})}_{\text{社会认知}}$$

  *(其中 $r_1, r_2$ 是 0 到 1 之间的随机数)*

- **更新位置 (Position Update):**

  $$x_{i}^{t+1} = x_{i}^{t} + v_{i}^{t+1}$$

- **边界处理:** 如果粒子飞出了定义域，将其拉回边界或做特殊处理。

**3. 评估与更新:**

- 计算新位置的适应度 $f(x_{i}^{t+1})$。
- **更新 Pbest:** 如果现在的适应度比自己的历史最好还好，就更新 $Pbest$。
- **更新 Gbest:** 如果现在的适应度比整个群体的历史最好还好，就更新 $Gbest$。

**终止:** 达到最大迭代次数或满足精度要求，输出 $Gbest$。

#### 优点

- 收敛速度快
- 参数少，实现简单
- 适合连续优化

#### 缺点

- 容易早熟，困死在局部
- 离散问题处理较弱

#### 适用场景

- 连续函数优化
- 电力系统优化